----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 1024, 14, 14]         787,456
        PatchEmbed-2            [-1, 196, 1024]               0
           Dropout-3            [-1, 197, 1024]               0
         LayerNorm-4            [-1, 197, 1024]           2,048
            Linear-5            [-1, 197, 3072]       3,148,800
           Dropout-6         [-1, 16, 197, 197]               0
            Linear-7            [-1, 197, 1024]       1,049,600
           Dropout-8            [-1, 197, 1024]               0
         Attention-9            [-1, 197, 1024]               0
         Identity-10            [-1, 197, 1024]               0
        LayerNorm-11            [-1, 197, 1024]           2,048
           Linear-12            [-1, 197, 4096]       4,198,400
             GELU-13            [-1, 197, 4096]               0
          Dropout-14            [-1, 197, 4096]               0
           Linear-15            [-1, 197, 1024]       4,195,328
          Dropout-16            [-1, 197, 1024]               0
              Mlp-17            [-1, 197, 1024]               0
         Identity-18            [-1, 197, 1024]               0
            Block-19            [-1, 197, 1024]               0
        LayerNorm-20            [-1, 197, 1024]           2,048
           Linear-21            [-1, 197, 3072]       3,148,800
          Dropout-22         [-1, 16, 197, 197]               0
           Linear-23            [-1, 197, 1024]       1,049,600
          Dropout-24            [-1, 197, 1024]               0
        Attention-25            [-1, 197, 1024]               0
         Identity-26            [-1, 197, 1024]               0
        LayerNorm-27            [-1, 197, 1024]           2,048
           Linear-28            [-1, 197, 4096]       4,198,400
             GELU-29            [-1, 197, 4096]               0
          Dropout-30            [-1, 197, 4096]               0
           Linear-31            [-1, 197, 1024]       4,195,328
          Dropout-32            [-1, 197, 1024]               0
              Mlp-33            [-1, 197, 1024]               0
         Identity-34            [-1, 197, 1024]               0
            Block-35            [-1, 197, 1024]               0
        LayerNorm-36            [-1, 197, 1024]           2,048
           Linear-37            [-1, 197, 3072]       3,148,800
          Dropout-38         [-1, 16, 197, 197]               0
           Linear-39            [-1, 197, 1024]       1,049,600
          Dropout-40            [-1, 197, 1024]               0
        Attention-41            [-1, 197, 1024]               0
         Identity-42            [-1, 197, 1024]               0
        LayerNorm-43            [-1, 197, 1024]           2,048
           Linear-44            [-1, 197, 4096]       4,198,400
             GELU-45            [-1, 197, 4096]               0
          Dropout-46            [-1, 197, 4096]               0
           Linear-47            [-1, 197, 1024]       4,195,328
          Dropout-48            [-1, 197, 1024]               0
              Mlp-49            [-1, 197, 1024]               0
         Identity-50            [-1, 197, 1024]               0
            Block-51            [-1, 197, 1024]               0
        LayerNorm-52            [-1, 197, 1024]           2,048
           Linear-53            [-1, 197, 3072]       3,148,800
          Dropout-54         [-1, 16, 197, 197]               0
           Linear-55            [-1, 197, 1024]       1,049,600
          Dropout-56            [-1, 197, 1024]               0
        Attention-57            [-1, 197, 1024]               0
         Identity-58            [-1, 197, 1024]               0
        LayerNorm-59            [-1, 197, 1024]           2,048
           Linear-60            [-1, 197, 4096]       4,198,400
             GELU-61            [-1, 197, 4096]               0
          Dropout-62            [-1, 197, 4096]               0
           Linear-63            [-1, 197, 1024]       4,195,328
          Dropout-64            [-1, 197, 1024]               0
              Mlp-65            [-1, 197, 1024]               0
         Identity-66            [-1, 197, 1024]               0
            Block-67            [-1, 197, 1024]               0
        LayerNorm-68            [-1, 197, 1024]           2,048
           Linear-69            [-1, 197, 3072]       3,148,800
          Dropout-70         [-1, 16, 197, 197]               0
           Linear-71            [-1, 197, 1024]       1,049,600
          Dropout-72            [-1, 197, 1024]               0
        Attention-73            [-1, 197, 1024]               0
         Identity-74            [-1, 197, 1024]               0
        LayerNorm-75            [-1, 197, 1024]           2,048
           Linear-76            [-1, 197, 4096]       4,198,400
             GELU-77            [-1, 197, 4096]               0
          Dropout-78            [-1, 197, 4096]               0
           Linear-79            [-1, 197, 1024]       4,195,328
          Dropout-80            [-1, 197, 1024]               0
              Mlp-81            [-1, 197, 1024]               0
         Identity-82            [-1, 197, 1024]               0
            Block-83            [-1, 197, 1024]               0
        LayerNorm-84            [-1, 197, 1024]           2,048
           Linear-85            [-1, 197, 3072]       3,148,800
          Dropout-86         [-1, 16, 197, 197]               0
           Linear-87            [-1, 197, 1024]       1,049,600
          Dropout-88            [-1, 197, 1024]               0
        Attention-89            [-1, 197, 1024]               0
         Identity-90            [-1, 197, 1024]               0
        LayerNorm-91            [-1, 197, 1024]           2,048
           Linear-92            [-1, 197, 4096]       4,198,400
             GELU-93            [-1, 197, 4096]               0
          Dropout-94            [-1, 197, 4096]               0
           Linear-95            [-1, 197, 1024]       4,195,328
          Dropout-96            [-1, 197, 1024]               0
              Mlp-97            [-1, 197, 1024]               0
         Identity-98            [-1, 197, 1024]               0
            Block-99            [-1, 197, 1024]               0
       LayerNorm-100            [-1, 197, 1024]           2,048
          Linear-101            [-1, 197, 3072]       3,148,800
         Dropout-102         [-1, 16, 197, 197]               0
          Linear-103            [-1, 197, 1024]       1,049,600
         Dropout-104            [-1, 197, 1024]               0
       Attention-105            [-1, 197, 1024]               0
        Identity-106            [-1, 197, 1024]               0
       LayerNorm-107            [-1, 197, 1024]           2,048
          Linear-108            [-1, 197, 4096]       4,198,400
            GELU-109            [-1, 197, 4096]               0
         Dropout-110            [-1, 197, 4096]               0
          Linear-111            [-1, 197, 1024]       4,195,328
         Dropout-112            [-1, 197, 1024]               0
             Mlp-113            [-1, 197, 1024]               0
        Identity-114            [-1, 197, 1024]               0
           Block-115            [-1, 197, 1024]               0
       LayerNorm-116            [-1, 197, 1024]           2,048
          Linear-117            [-1, 197, 3072]       3,148,800
         Dropout-118         [-1, 16, 197, 197]               0
          Linear-119            [-1, 197, 1024]       1,049,600
         Dropout-120            [-1, 197, 1024]               0
       Attention-121            [-1, 197, 1024]               0
        Identity-122            [-1, 197, 1024]               0
       LayerNorm-123            [-1, 197, 1024]           2,048
          Linear-124            [-1, 197, 4096]       4,198,400
            GELU-125            [-1, 197, 4096]               0
         Dropout-126            [-1, 197, 4096]               0
          Linear-127            [-1, 197, 1024]       4,195,328
         Dropout-128            [-1, 197, 1024]               0
             Mlp-129            [-1, 197, 1024]               0
        Identity-130            [-1, 197, 1024]               0
           Block-131            [-1, 197, 1024]               0
       LayerNorm-132            [-1, 197, 1024]           2,048
          Linear-133            [-1, 197, 3072]       3,148,800
         Dropout-134         [-1, 16, 197, 197]               0
          Linear-135            [-1, 197, 1024]       1,049,600
         Dropout-136            [-1, 197, 1024]               0
       Attention-137            [-1, 197, 1024]               0
        Identity-138            [-1, 197, 1024]               0
       LayerNorm-139            [-1, 197, 1024]           2,048
          Linear-140            [-1, 197, 4096]       4,198,400
            GELU-141            [-1, 197, 4096]               0
         Dropout-142            [-1, 197, 4096]               0
          Linear-143            [-1, 197, 1024]       4,195,328
         Dropout-144            [-1, 197, 1024]               0
             Mlp-145            [-1, 197, 1024]               0
        Identity-146            [-1, 197, 1024]               0
           Block-147            [-1, 197, 1024]               0
       LayerNorm-148            [-1, 197, 1024]           2,048
          Linear-149            [-1, 197, 3072]       3,148,800
         Dropout-150         [-1, 16, 197, 197]               0
          Linear-151            [-1, 197, 1024]       1,049,600
         Dropout-152            [-1, 197, 1024]               0
       Attention-153            [-1, 197, 1024]               0
        Identity-154            [-1, 197, 1024]               0
       LayerNorm-155            [-1, 197, 1024]           2,048
          Linear-156            [-1, 197, 4096]       4,198,400
            GELU-157            [-1, 197, 4096]               0
         Dropout-158            [-1, 197, 4096]               0
          Linear-159            [-1, 197, 1024]       4,195,328
         Dropout-160            [-1, 197, 1024]               0
             Mlp-161            [-1, 197, 1024]               0
        Identity-162            [-1, 197, 1024]               0
           Block-163            [-1, 197, 1024]               0
       LayerNorm-164            [-1, 197, 1024]           2,048
          Linear-165            [-1, 197, 3072]       3,148,800
         Dropout-166         [-1, 16, 197, 197]               0
          Linear-167            [-1, 197, 1024]       1,049,600
         Dropout-168            [-1, 197, 1024]               0
       Attention-169            [-1, 197, 1024]               0
        Identity-170            [-1, 197, 1024]               0
       LayerNorm-171            [-1, 197, 1024]           2,048
          Linear-172            [-1, 197, 4096]       4,198,400
            GELU-173            [-1, 197, 4096]               0
         Dropout-174            [-1, 197, 4096]               0
          Linear-175            [-1, 197, 1024]       4,195,328
         Dropout-176            [-1, 197, 1024]               0
             Mlp-177            [-1, 197, 1024]               0
        Identity-178            [-1, 197, 1024]               0
           Block-179            [-1, 197, 1024]               0
       LayerNorm-180            [-1, 197, 1024]           2,048
          Linear-181            [-1, 197, 3072]       3,148,800
         Dropout-182         [-1, 16, 197, 197]               0
          Linear-183            [-1, 197, 1024]       1,049,600
         Dropout-184            [-1, 197, 1024]               0
       Attention-185            [-1, 197, 1024]               0
        Identity-186            [-1, 197, 1024]               0
       LayerNorm-187            [-1, 197, 1024]           2,048
          Linear-188            [-1, 197, 4096]       4,198,400
            GELU-189            [-1, 197, 4096]               0
         Dropout-190            [-1, 197, 4096]               0
          Linear-191            [-1, 197, 1024]       4,195,328
         Dropout-192            [-1, 197, 1024]               0
             Mlp-193            [-1, 197, 1024]               0
        Identity-194            [-1, 197, 1024]               0
           Block-195            [-1, 197, 1024]               0
       LayerNorm-196            [-1, 197, 1024]           2,048
          Linear-197            [-1, 197, 3072]       3,148,800
         Dropout-198         [-1, 16, 197, 197]               0
          Linear-199            [-1, 197, 1024]       1,049,600
         Dropout-200            [-1, 197, 1024]               0
       Attention-201            [-1, 197, 1024]               0
        Identity-202            [-1, 197, 1024]               0
       LayerNorm-203            [-1, 197, 1024]           2,048
          Linear-204            [-1, 197, 4096]       4,198,400
            GELU-205            [-1, 197, 4096]               0
         Dropout-206            [-1, 197, 4096]               0
          Linear-207            [-1, 197, 1024]       4,195,328
         Dropout-208            [-1, 197, 1024]               0
             Mlp-209            [-1, 197, 1024]               0
        Identity-210            [-1, 197, 1024]               0
           Block-211            [-1, 197, 1024]               0
       LayerNorm-212            [-1, 197, 1024]           2,048
          Linear-213            [-1, 197, 3072]       3,148,800
         Dropout-214         [-1, 16, 197, 197]               0
          Linear-215            [-1, 197, 1024]       1,049,600
         Dropout-216            [-1, 197, 1024]               0
       Attention-217            [-1, 197, 1024]               0
        Identity-218            [-1, 197, 1024]               0
       LayerNorm-219            [-1, 197, 1024]           2,048
          Linear-220            [-1, 197, 4096]       4,198,400
            GELU-221            [-1, 197, 4096]               0
         Dropout-222            [-1, 197, 4096]               0
          Linear-223            [-1, 197, 1024]       4,195,328
         Dropout-224            [-1, 197, 1024]               0
             Mlp-225            [-1, 197, 1024]               0
        Identity-226            [-1, 197, 1024]               0
           Block-227            [-1, 197, 1024]               0
       LayerNorm-228            [-1, 197, 1024]           2,048
          Linear-229            [-1, 197, 3072]       3,148,800
         Dropout-230         [-1, 16, 197, 197]               0
          Linear-231            [-1, 197, 1024]       1,049,600
         Dropout-232            [-1, 197, 1024]               0
       Attention-233            [-1, 197, 1024]               0
        Identity-234            [-1, 197, 1024]               0
       LayerNorm-235            [-1, 197, 1024]           2,048
          Linear-236            [-1, 197, 4096]       4,198,400
            GELU-237            [-1, 197, 4096]               0
         Dropout-238            [-1, 197, 4096]               0
          Linear-239            [-1, 197, 1024]       4,195,328
         Dropout-240            [-1, 197, 1024]               0
             Mlp-241            [-1, 197, 1024]               0
        Identity-242            [-1, 197, 1024]               0
           Block-243            [-1, 197, 1024]               0
       LayerNorm-244            [-1, 197, 1024]           2,048
          Linear-245            [-1, 197, 3072]       3,148,800
         Dropout-246         [-1, 16, 197, 197]               0
          Linear-247            [-1, 197, 1024]       1,049,600
         Dropout-248            [-1, 197, 1024]               0
       Attention-249            [-1, 197, 1024]               0
        Identity-250            [-1, 197, 1024]               0
       LayerNorm-251            [-1, 197, 1024]           2,048
          Linear-252            [-1, 197, 4096]       4,198,400
            GELU-253            [-1, 197, 4096]               0
         Dropout-254            [-1, 197, 4096]               0
          Linear-255            [-1, 197, 1024]       4,195,328
         Dropout-256            [-1, 197, 1024]               0
             Mlp-257            [-1, 197, 1024]               0
        Identity-258            [-1, 197, 1024]               0
           Block-259            [-1, 197, 1024]               0
       LayerNorm-260            [-1, 197, 1024]           2,048
          Linear-261            [-1, 197, 3072]       3,148,800
         Dropout-262         [-1, 16, 197, 197]               0
          Linear-263            [-1, 197, 1024]       1,049,600
         Dropout-264            [-1, 197, 1024]               0
       Attention-265            [-1, 197, 1024]               0
        Identity-266            [-1, 197, 1024]               0
       LayerNorm-267            [-1, 197, 1024]           2,048
          Linear-268            [-1, 197, 4096]       4,198,400
            GELU-269            [-1, 197, 4096]               0
         Dropout-270            [-1, 197, 4096]               0
          Linear-271            [-1, 197, 1024]       4,195,328
         Dropout-272            [-1, 197, 1024]               0
             Mlp-273            [-1, 197, 1024]               0
        Identity-274            [-1, 197, 1024]               0
           Block-275            [-1, 197, 1024]               0
       LayerNorm-276            [-1, 197, 1024]           2,048
          Linear-277            [-1, 197, 3072]       3,148,800
         Dropout-278         [-1, 16, 197, 197]               0
          Linear-279            [-1, 197, 1024]       1,049,600
         Dropout-280            [-1, 197, 1024]               0
       Attention-281            [-1, 197, 1024]               0
        Identity-282            [-1, 197, 1024]               0
       LayerNorm-283            [-1, 197, 1024]           2,048
          Linear-284            [-1, 197, 4096]       4,198,400
            GELU-285            [-1, 197, 4096]               0
         Dropout-286            [-1, 197, 4096]               0
          Linear-287            [-1, 197, 1024]       4,195,328
         Dropout-288            [-1, 197, 1024]               0
             Mlp-289            [-1, 197, 1024]               0
        Identity-290            [-1, 197, 1024]               0
           Block-291            [-1, 197, 1024]               0
       LayerNorm-292            [-1, 197, 1024]           2,048
          Linear-293            [-1, 197, 3072]       3,148,800
         Dropout-294         [-1, 16, 197, 197]               0
          Linear-295            [-1, 197, 1024]       1,049,600
         Dropout-296            [-1, 197, 1024]               0
       Attention-297            [-1, 197, 1024]               0
        Identity-298            [-1, 197, 1024]               0
       LayerNorm-299            [-1, 197, 1024]           2,048
          Linear-300            [-1, 197, 4096]       4,198,400
            GELU-301            [-1, 197, 4096]               0
         Dropout-302            [-1, 197, 4096]               0
          Linear-303            [-1, 197, 1024]       4,195,328
         Dropout-304            [-1, 197, 1024]               0
             Mlp-305            [-1, 197, 1024]               0
        Identity-306            [-1, 197, 1024]               0
           Block-307            [-1, 197, 1024]               0
       LayerNorm-308            [-1, 197, 1024]           2,048
          Linear-309            [-1, 197, 3072]       3,148,800
         Dropout-310         [-1, 16, 197, 197]               0
          Linear-311            [-1, 197, 1024]       1,049,600
         Dropout-312            [-1, 197, 1024]               0
       Attention-313            [-1, 197, 1024]               0
        Identity-314            [-1, 197, 1024]               0
       LayerNorm-315            [-1, 197, 1024]           2,048
          Linear-316            [-1, 197, 4096]       4,198,400
            GELU-317            [-1, 197, 4096]               0
         Dropout-318            [-1, 197, 4096]               0
          Linear-319            [-1, 197, 1024]       4,195,328
         Dropout-320            [-1, 197, 1024]               0
             Mlp-321            [-1, 197, 1024]               0
        Identity-322            [-1, 197, 1024]               0
           Block-323            [-1, 197, 1024]               0
       LayerNorm-324            [-1, 197, 1024]           2,048
          Linear-325            [-1, 197, 3072]       3,148,800
         Dropout-326         [-1, 16, 197, 197]               0
          Linear-327            [-1, 197, 1024]       1,049,600
         Dropout-328            [-1, 197, 1024]               0
       Attention-329            [-1, 197, 1024]               0
        Identity-330            [-1, 197, 1024]               0
       LayerNorm-331            [-1, 197, 1024]           2,048
          Linear-332            [-1, 197, 4096]       4,198,400
            GELU-333            [-1, 197, 4096]               0
         Dropout-334            [-1, 197, 4096]               0
          Linear-335            [-1, 197, 1024]       4,195,328
         Dropout-336            [-1, 197, 1024]               0
             Mlp-337            [-1, 197, 1024]               0
        Identity-338            [-1, 197, 1024]               0
           Block-339            [-1, 197, 1024]               0
       LayerNorm-340            [-1, 197, 1024]           2,048
          Linear-341            [-1, 197, 3072]       3,148,800
         Dropout-342         [-1, 16, 197, 197]               0
          Linear-343            [-1, 197, 1024]       1,049,600
         Dropout-344            [-1, 197, 1024]               0
       Attention-345            [-1, 197, 1024]               0
        Identity-346            [-1, 197, 1024]               0
       LayerNorm-347            [-1, 197, 1024]           2,048
          Linear-348            [-1, 197, 4096]       4,198,400
            GELU-349            [-1, 197, 4096]               0
         Dropout-350            [-1, 197, 4096]               0
          Linear-351            [-1, 197, 1024]       4,195,328
         Dropout-352            [-1, 197, 1024]               0
             Mlp-353            [-1, 197, 1024]               0
        Identity-354            [-1, 197, 1024]               0
           Block-355            [-1, 197, 1024]               0
       LayerNorm-356            [-1, 197, 1024]           2,048
          Linear-357            [-1, 197, 3072]       3,148,800
         Dropout-358         [-1, 16, 197, 197]               0
          Linear-359            [-1, 197, 1024]       1,049,600
         Dropout-360            [-1, 197, 1024]               0
       Attention-361            [-1, 197, 1024]               0
        Identity-362            [-1, 197, 1024]               0
       LayerNorm-363            [-1, 197, 1024]           2,048
          Linear-364            [-1, 197, 4096]       4,198,400
            GELU-365            [-1, 197, 4096]               0
         Dropout-366            [-1, 197, 4096]               0
          Linear-367            [-1, 197, 1024]       4,195,328
         Dropout-368            [-1, 197, 1024]               0
             Mlp-369            [-1, 197, 1024]               0
        Identity-370            [-1, 197, 1024]               0
           Block-371            [-1, 197, 1024]               0
       LayerNorm-372            [-1, 197, 1024]           2,048
          Linear-373            [-1, 197, 3072]       3,148,800
         Dropout-374         [-1, 16, 197, 197]               0
          Linear-375            [-1, 197, 1024]       1,049,600
         Dropout-376            [-1, 197, 1024]               0
       Attention-377            [-1, 197, 1024]               0
        Identity-378            [-1, 197, 1024]               0
       LayerNorm-379            [-1, 197, 1024]           2,048
          Linear-380            [-1, 197, 4096]       4,198,400
            GELU-381            [-1, 197, 4096]               0
         Dropout-382            [-1, 197, 4096]               0
          Linear-383            [-1, 197, 1024]       4,195,328
         Dropout-384            [-1, 197, 1024]               0
             Mlp-385            [-1, 197, 1024]               0
        Identity-386            [-1, 197, 1024]               0
           Block-387            [-1, 197, 1024]               0
       LayerNorm-388                 [-1, 1024]           2,048
          Conv2d-389         [-1, 64, 128, 128]           3,136
       LeakyReLU-390         [-1, 64, 128, 128]               0
          Conv2d-391          [-1, 128, 64, 64]         131,200
     BatchNorm2d-392          [-1, 128, 64, 64]             256
      downsample-393          [-1, 128, 64, 64]               0
       LeakyReLU-394          [-1, 128, 64, 64]               0
          Conv2d-395          [-1, 256, 32, 32]         524,544
     BatchNorm2d-396          [-1, 256, 32, 32]             512
      downsample-397          [-1, 256, 32, 32]               0
       LeakyReLU-398          [-1, 256, 32, 32]               0
          Conv2d-399          [-1, 512, 16, 16]       2,097,664
     BatchNorm2d-400          [-1, 512, 16, 16]           1,024
      downsample-401          [-1, 512, 16, 16]               0
       LeakyReLU-402          [-1, 512, 16, 16]               0
          Conv2d-403            [-1, 512, 8, 8]       4,194,816
     BatchNorm2d-404            [-1, 512, 8, 8]           1,024
      downsample-405            [-1, 512, 8, 8]               0
       LeakyReLU-406            [-1, 512, 8, 8]               0
          Conv2d-407            [-1, 512, 4, 4]       4,194,816
     BatchNorm2d-408            [-1, 512, 4, 4]           1,024
      downsample-409            [-1, 512, 4, 4]               0
       LeakyReLU-410            [-1, 512, 4, 4]               0
          Conv2d-411            [-1, 512, 2, 2]       4,194,816
     BatchNorm2d-412            [-1, 512, 2, 2]           1,024
      downsample-413            [-1, 512, 2, 2]               0
       LeakyReLU-414            [-1, 512, 2, 2]               0
          Conv2d-415            [-1, 512, 1, 1]       4,194,816
     BatchNorm2d-416            [-1, 512, 1, 1]           1,024
      downsample-417            [-1, 512, 1, 1]               0
            ReLU-418            [-1, 512, 1, 1]               0
 ConvTranspose2d-419            [-1, 512, 2, 2]       4,194,816
     BatchNorm2d-420            [-1, 512, 2, 2]           1,024
        Identity-421            [-1, 512, 2, 2]               0
        upsample-422            [-1, 512, 2, 2]               0
            ReLU-423           [-1, 1024, 2, 2]               0
 ConvTranspose2d-424            [-1, 512, 4, 4]       8,389,120
     BatchNorm2d-425            [-1, 512, 4, 4]           1,024
         Dropout-426            [-1, 512, 4, 4]               0
        upsample-427            [-1, 512, 4, 4]               0
            ReLU-428           [-1, 1024, 4, 4]               0
 ConvTranspose2d-429            [-1, 512, 8, 8]       8,389,120
     BatchNorm2d-430            [-1, 512, 8, 8]           1,024
         Dropout-431            [-1, 512, 8, 8]               0
        upsample-432            [-1, 512, 8, 8]               0
            ReLU-433           [-1, 1024, 8, 8]               0
 ConvTranspose2d-434          [-1, 512, 16, 16]       8,389,120
     BatchNorm2d-435          [-1, 512, 16, 16]           1,024
        Identity-436          [-1, 512, 16, 16]               0
        upsample-437          [-1, 512, 16, 16]               0
            ReLU-438         [-1, 1024, 16, 16]               0
 ConvTranspose2d-439          [-1, 256, 32, 32]       4,194,560
     BatchNorm2d-440          [-1, 256, 32, 32]             512
        Identity-441          [-1, 256, 32, 32]               0
        upsample-442          [-1, 256, 32, 32]               0
            ReLU-443          [-1, 512, 32, 32]               0
 ConvTranspose2d-444          [-1, 128, 64, 64]       1,048,704
     BatchNorm2d-445          [-1, 128, 64, 64]             256
        Identity-446          [-1, 128, 64, 64]               0
        upsample-447          [-1, 128, 64, 64]               0
            ReLU-448          [-1, 256, 64, 64]               0
 ConvTranspose2d-449         [-1, 64, 128, 128]         262,208
     BatchNorm2d-450         [-1, 64, 128, 128]             128
        Identity-451         [-1, 64, 128, 128]               0
        upsample-452         [-1, 64, 128, 128]               0
 ConvTranspose2d-453          [-1, 3, 256, 256]           6,147
            Tanh-454          [-1, 3, 256, 256]               0
================================================================
Total params: 357,519,363
Trainable params: 357,519,363
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.75
Forward/backward pass size (MB): 1202.98
Params size (MB): 1363.83
Estimated Total Size (MB): 2567.56
----------------------------------------------------------------